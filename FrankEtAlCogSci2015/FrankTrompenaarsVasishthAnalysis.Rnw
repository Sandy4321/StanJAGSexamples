\documentclass{article}

\title{Data analysis for Frank, Trompenaars, Vasishth CogSci 2015 paper entitled:\\
Cross-linguistic differences in processing double-embedded relative clauses: Working-memory constraints or language statistics?}

\author{Shravan Vasishth and Stefan Frank}

\begin{document}
\SweaveOpts{concordance=TRUE}

\section{Load data}

<<>>=
library(rstan)

library(lme4)
## load data:
data_nl_nl <- read.csv('data/RTdata_nl_nl.csv',header=TRUE)
data_de_en <- read.csv('data/RTdata_de_en.csv',header=TRUE)
data_nl_en <- read.csv('data/RTdata_nl_en.csv',header=TRUE)
@

In the frequentist (models) models, because item-level variance was nearly zero in the Dutch data, for consistency we fit varying slopes by subject only. Variance was zero or near zero because we do not have enough data to estimate all variance components for items.

In the Stan models, we fit a full variance covariance matrix by subjects and by items; this is possible because we can specify mildly informative priors for the variance components. The prior will dominate unless enough data is available for the likelihood to play a role in determining the posterior. 


\section{Dutch subjects tested on Dutch}


<<>>=
summary(data_nl_nl)
## contrast coding:
#grammatical condition was coded as +1,
#ungrammatical as -1

# Dutch subjects tested in Dutch
##Item level variance is 0:
model0_nl_nl_V3 <- lmer(V3  ~ 1 + 
                         (1|subject) + 
#                         (1|item) + 
                         (0+condition|subject),
                       data_nl_nl,REML="FALSE")

model1_nl_nl_V3 <- lmer(V3  ~ condition + 
                         (1|subject) + 
#                        (1|item) + 
                         (0+condition|subject),
                       data_nl_nl,REML="FALSE")



library(xtable)

nl_nl_V3_anova<-anova(model0_nl_nl_V3,model1_nl_nl_V3)

nl_nl_chisq<-matrix(rep(NA,5*3),ncol=3)

## V3 anova results:
nl_nl_chisq[1,]<-
## Chisq:
c(nl_nl_V3_anova$"Chisq"[2],
## Df:
nl_nl_V3_anova$"Chi Df"[2],
## P-val:
nl_nl_V3_anova$"Pr"[2])

model0_nl_nl_D1 <- lmer(NP1 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_nl_nl,
                        REML="FALSE")

model1_nl_nl_D1 <- lmer(NP1 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_nl,
                        REML="FALSE")

### item level variance 0:
model2_nl_nl_D1 <- lmer(NP1 ~ condition + (1|subject) + (1|item) + (0+condition|subject) + (0+condition|item),data_nl_nl,
                        REML="FALSE")

nl_nl_D1_anova<-anova(model0_nl_nl_D1,model1_nl_nl_D1)

## D1 anova results:
nl_nl_chisq[2,]<-
## Chisq:
c(nl_nl_D1_anova$"Chisq"[2],
## Df:
nl_nl_D1_anova$"Chi Df"[2],
## P-val:
nl_nl_D1_anova$"Pr"[2])


## N1:
model0_nl_nl_N1 <- lmer(NP2 ~ 1 + (1|subject) + 
                          (1|item) + 
                          (0+condition|subject),
                        data_nl_nl,REML="FALSE")

model1_nl_nl_N1 <- lmer(NP2 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_nl,REML="FALSE")

nl_nl_N1_anova<-anova(model0_nl_nl_N1,model1_nl_nl_N1)

nl_nl_chisq[3,]<-
## Chisq:
c(nl_nl_N1_anova$"Chisq"[2],
## Df:
nl_nl_N1_anova$"Chi Df"[2],
## P-val:
nl_nl_N1_anova$"Pr"[2])

## P:
model0_nl_nl_P  <- lmer(PP1 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),
                        data_nl_nl,REML="FALSE")

model1_nl_nl_P  <- lmer(PP1 ~ condition + 
                          (1|subject) + (1|item) + 
                          (0+condition|subject),data_nl_nl,REML="FALSE")

nl_nl_P_anova<-anova(model0_nl_nl_P,model1_nl_nl_P)

nl_nl_chisq[4,]<-
## Chisq:
c(nl_nl_P_anova$"Chisq"[2],
## Df:
nl_nl_P_anova$"Chi Df"[2],
## P-val:
nl_nl_P_anova$"Pr"[2])

## D2:
model0_nl_nl_D2 <- lmer(PP2 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_nl_nl,
                        REML="FALSE")

model1_nl_nl_D2 <- lmer(PP2 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_nl,
                        REML="FALSE")

nl_nl_D2_anova<-anova(model0_nl_nl_D2,model1_nl_nl_D2)

nl_nl_chisq[5,]<-
## Chisq:
c(nl_nl_D2_anova$"Chisq"[2],
## Df:
nl_nl_D2_anova$"Chi Df"[2],
## P-val:
nl_nl_D2_anova$"Pr"[2])
@

\subsection{Stan models}

<<>>=
## function for setting up data:
prepare_data<-function(col=8){
dat <- list(mu_prior=c(0,0),
            subject=as.integer(factor(data_nl_nl$subject)),
            item=as.integer(factor(data_nl_nl$item)),
            y=data_nl_nl[,col], ## dep. var.
            condition = data_nl_nl$condition,
            N = nrow(data_nl_nl),
            I = length(unique(data_nl_nl$subject)),
            K = length(unique(data_nl_nl$item))
)
return(dat)
}

params<-c("beta","sigma_e","sigma_u","sigma_w")

colnames(data_nl_nl)

## columns in data:
#V3 V3 8
#D1 NP1 9
#N1 NP2 10
#P PP1 11
#D2 PP2 12

datV3<-prepare_data(col=8)

fit_V3 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datV3,
                 pars=params)

print(fit_V3)

mV3<-as.matrix(fit_V3)
head(mV3)
hist(mV3[,2])
hist(mV3[,3])
hist(mV3[,4])
hist(mV3[,5])
hist(mV3[,6])
hist(mV3[,7])

deenV3results<-c(mean(mV3[,2]),
                 sd(mV3[,2]),
                 quantile(mV3[,2],
                          probs=c(0.025,0.975)),
                mean(mV3[,2]<0))

datD1<-prepare_data(col=9)

fit_D1 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD1,
                 pars=params)

print(fit_D1)

mD1<-as.matrix(fit_D1)

deenD1results<-c(mean(mD1[,2]),
                 sd(mD1[,2]),
                 quantile(mD1[,2],
                          probs=c(0.025,0.975)),
                mean(mD1[,2]<0))

datN1<-prepare_data(col=10)

fit_N1 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datN1,
                 pars=params)

print(fit_N1)

mN1<-as.matrix(fit_N1)

nlnlN1results<-c(mean(mN1[,2]),
                 sd(mN1[,2]),
                 quantile(mN1[,2],
                          probs=c(0.025,0.975)),
                mean(mN1[,2]<0))

datP<-prepare_data(col=11)

fit_P <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datP,
                 pars=params)

print(fit_P)

mP<-as.matrix(fit_P)

nlnlPresults<-c(mean(mP[,2]),
                 sd(mP[,2]),
                 quantile(mP[,2],
                          probs=c(0.025,0.975)),
                mean(mP[,2]<0))

datD2<-prepare_data(col=12)

fit_D2 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD2,
                 pars=params)

mD2<-as.matrix(fit_D2)

nlnlD2results<-c(mean(mD2[,2]),
                 sd(mD2[,2]),
                 quantile(mD2[,2],
                          probs=c(0.025,0.975)),
                mean(mD2[,2]<0))
@

Assembling the results for NL-NL:

<<>>=
#V3 V3 8
#D1 NP1 9
#N1 NP2 10
#P PP1 11
#D2 PP2 12
nlnlresults<-rbind(nlnlV3results,
      nlnlD1results,
      nlnlN1results,
      nlnlPresults,
      nlnlD2results)

nlnlresults<-cbind(nlnlresults,nl_nl_chisq[,c(1,3)])
colnames(nlnlresults)<-c("b","SD","2.5th","97.5th",
                         "P(b<0)","Chi-sq","p-value")

rownames(nlnlresults)<-c("V3","Det1","N1","Prep","Det2")
@



<<results=tex>>=
library(xtable)
xtable(nlnlresults)
@

\section{German speakers reading English}

\subsection{Preprocessing proficiency scores}

<<>>=
deprof<-read.table("data/GermanProficiencyData.txt",header=TRUE)

deprof$subj<-paste("de",deprof$NR,sep="")

length(unique(deprof$subj))
data_de_en
length(unique(data_de_en$subject))

deprof<-deprof[,c(7,8)]

data_de_en2<-merge(data_de_en,deprof,by.x="subject",by.y="subj")
dim(data_de_en)
dim(data_de_en2)
data_de_en2$proficiency<-data_de_en2$New
colnames(data_de_en2)
data_de_en2<-data_de_en2[,c(1:14)]
data_de_en<-data_de_en2
@

<<>>=
model0_de_en_V3 = lmer(V3  ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML="FALSE")
model1_de_en_V3 = lmer(V3  ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML="FALSE")

de_en_V3_anova<-anova(model0_de_en_V3,
                      model1_de_en_V3)
de_en_chisq<-matrix(rep(NA,5*3),ncol=3)

de_en_chisq[1,]<-
  ## Chisq:
c(de_en_V3_anova$"Chisq"[2],
## Df:
de_en_V3_anova$"Chi Df"[2],
## P-val:
de_en_V3_anova$"Pr"[2])

model0_de_en_D1 = lmer(NP1 ~ 1+
                      + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)
model1_de_en_D1 = lmer(NP1 ~ condition 
                      + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)

de_en_D1_anova<-anova(model0_de_en_D1,
                      model1_de_en_D1)

de_en_chisq[2,]<-
  ## Chisq:
c(de_en_D1_anova$"Chisq"[2],
## Df:
de_en_D1_anova$"Chi Df"[2],
## P-val:
de_en_D1_anova$"Pr"[2])

model0_de_en_N1 = lmer(NP2 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)

model1_de_en_N1 = lmer(NP2 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)

de_en_N1_anova<-anova(model0_de_en_N1,
                      model1_de_en_N1)

de_en_chisq[3,]<-
  ## Chisq:
c(de_en_N1_anova$"Chisq"[2],
## Df:
de_en_N1_anova$"Chi Df"[2],
## P-val:
de_en_N1_anova$"Pr"[2])

model0_de_en_P  = lmer(PP1 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)

model1_de_en_P  = lmer(PP1 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)

de_en_P_anova<-anova(model0_de_en_P,
                      model1_de_en_P)

de_en_chisq[4,]<-
  ## Chisq:
c(de_en_P_anova$"Chisq"[2],
## Df:
de_en_P_anova$"Chi Df"[2],
## P-val:
de_en_P_anova$"Pr"[2])

model0_de_en_D2 = lmer(PP2 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)

model1_de_en_D2 = lmer(PP2 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_de_en,REML=FALSE)

de_en_D2_anova<-anova(model0_de_en_D2,
                      model1_de_en_D2)

de_en_chisq[5,]<-
  ## Chisq:
c(de_en_D2_anova$"Chisq"[2],
## Df:
de_en_D2_anova$"Chi Df"[2],
## P-val:
de_en_D2_anova$"Pr"[2])

@

\subsection{Stan model of Germans reading English}


<<>>=
## function for setting up data:
prepare_data<-function(col=9){
dat <- list(mu_prior=c(0,0),
            subject=as.integer(factor(data_de_en$subject)),
            item=as.integer(factor(data_de_en$item)),
            y=data_de_en[,col], ## dep. var.
            condition = data_de_en$condition,
            N = nrow(data_de_en),
            I = length(unique(data_de_en$subject)),
            K = length(unique(data_de_en$item))
)
return(dat)
}

## columns in data:
#V3 V3 9
#D1 NP1 10
#N1 NP2 11
#P PP1 12
#D2 PP2 13
colnames(data_de_en)[9:13]
@

<<>>=
datV3<-prepare_data(col=9)

summary(datV3$y)

fit_V3 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datV3,
                 pars=params)

mV3<-as.matrix(fit_V3)
head(mV3)
hist(mV3[,2])
hist(mV3[,3])
hist(mV3[,4])
hist(mV3[,5])
hist(mV3[,6])
hist(mV3[,7])

deenV3results<-c(mean(mV3[,2]),
                 sd(mV3[,2]),
                 quantile(mV3[,2],
                          probs=c(0.025,0.975)),
                mean(mV3[,2]>0))

@


<<>>=
datD1<-prepare_data(col=10)

summary(datD1$y)

fit_D1 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD1,
                 pars=params)

print(fit_D1)

mD1<-as.matrix(fit_D1)
head(mD1)

deenD1results<-c(mean(mD1[,2]),
                 sd(mD1[,2]),
                 quantile(mD1[,2],
                          probs=c(0.025,0.975)),
                mean(mD1[,2]>0))
@

This is the analysis for the main effect of proficiency and grammaticality$\times$proficiency interaction at Det1.

<<>>=
data_de_enprof<-subset(data_de_en,proficiency!="NA")

m0<-lmer(NP1~condition+scale(proficiency,scale=FALSE)+(condition||subject),data_de_enprof)

m1<-lmer(NP1~condition*scale(proficiency,scale=FALSE)+
           (condition||subject),data_de_enprof)

anova(m0,m1)

m2<-lmer(NP1~condition+scale(targetpos,scale=FALSE)+
           (condition||subject),
         data_de_enprof)

m3<-lmer(NP1~condition*scale(targetpos,scale=FALSE)+
           (condition||subject),
         data_de_enprof)

anova(m2,m3)
##chisq 0.63, 0.428




summary(m3)
##-0.005012, SE 0.00633, t=-0.79

proficiency<-data_de_enprof$proficiency-
  mean(data_de_enprof$proficiency)
interaction<-proficiency*data_de_enprof$condition

datD1prof <- list(mu_prior=c(0,0,0,0),
            subject=as.integer(factor(data_de_enprof$subject)),
            item=as.integer(factor(data_de_enprof$item)),
            y=data_de_enprof[,10], ## dep. var.
            condition = data_de_enprof$condition,
            proficiency = proficiency,
            interaction =  interaction,
            N = nrow(data_de_enprof),
            I = length(unique(data_de_enprof$subject)),
            K = length(unique(data_de_enprof$item)))

fit_D1prof <- stan(file="FTVCogSciProficiency.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD1prof,
                 pars=params)

print(fit_D1prof)

mD1prof<-as.matrix(fit_D1prof)
hist(mD1prof[,1])
hist(mD1prof[,2])
hist(mD1prof[,3])
hist(mD1prof[,4])
mean(mD1prof[,4]>0)
quantile(mD1prof[,4],prob=c(0.025,0.975))
mean(mD1prof[,4])
@


<<>>=
datN1<-prepare_data(col=11)

summary(datN1$y)

fit_N1 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datN1,
                 pars=params)

print(fit_N1)

mN1<-as.matrix(fit_N1)
head(mN1)

deenN1results<-c(mean(mN1[,2]),
                 sd(mN1[,2]),
                 quantile(mN1[,2],
                          probs=c(0.025,0.975)),
                mean(mN1[,2]>0))
@


<<>>=
datP<-prepare_data(col=12)

summary(datP$y)

fit_P <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datP,
                 pars=params)

print(fit_P)

mP<-as.matrix(fit_P)
head(mP)

deenPresults<-c(mean(mP[,2]),
                 sd(mP[,2]),
                 quantile(mP[,2],
                          probs=c(0.025,0.975)),
                mean(mP[,2]>0))
@

<<>>=
datD2<-prepare_data(col=13)

summary(datD2$y)

fit_D2 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD2,
                 pars=params)

print(fit_D2)

mD2<-as.matrix(fit_D2)
head(mD2)

deenD2results<-c(mean(mD2[,2]),
                 sd(mD2[,2]),
                 quantile(mD2[,2],
                          probs=c(0.025,0.975)),
                mean(mD2[,2]>0))
@

<<>>=
deenresults<-rbind(deenV3results,
      deenD1results,
      deenN1results,
      deenPresults,
      deenD2results)

deenresults<-cbind(deenresults,de_en_chisq[,c(1,3)])
colnames(deenresults)<-c("b","SD","2.5th","97.5th",
                         "P(b>0)","Chi-sq","p-value")

rownames(deenresults)<-c("V3","Det1","N1","Prep","Det2")

@

<<results=tex>>=
xtable(deenresults)
@

\section{Dutch speakers reading English}

<<>>=
model0_nl_en_V3 = lmer(V3 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

model1_nl_en_V3 = lmer(V3 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

nl_en_V3_anova<-anova(model0_nl_en_V3,
                      model1_nl_en_V3)

nl_en_chisq<-matrix(rep(NA,5*3),ncol=3)

nl_en_chisq[1,]<-
  ## Chisq:
c(nl_en_V3_anova$"Chisq"[2],
## Df:
nl_en_V3_anova$"Chi Df"[2],
## P-val:
nl_en_V3_anova$"Pr"[2])


model0_nl_en_D1 = lmer(NP1 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,REML=FALSE)

model1_nl_en_D1 = lmer(NP1 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,REML=FALSE)

nl_en_D1_anova<-anova(model0_nl_en_D1,model1_nl_en_D1)

nl_en_chisq[2,]<-
  ## Chisq:
c(nl_en_D1_anova$"Chisq"[2],
## Df:
nl_en_D1_anova$"Chi Df"[2],
## P-val:
nl_en_D1_anova$"Pr"[2])

model0_nl_en_N1 = lmer(NP2 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

model1_nl_en_N1 = lmer(NP2 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

nl_en_N1_anova<-anova(model0_nl_en_N1,
                      model1_nl_en_N1)

nl_en_chisq[3,]<-
  ## Chisq:
c(nl_en_N1_anova$"Chisq"[2],
## Df:
nl_en_N1_anova$"Chi Df"[2],
## P-val:
nl_en_N1_anova$"Pr"[2])

model0_nl_en_P  = lmer(PP1 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

model1_nl_en_P  = lmer(PP1 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

nl_en_P_anova<-anova(model0_nl_en_P,
                      model1_nl_en_P)

nl_en_chisq[4,]<-
  ## Chisq:
c(nl_en_P_anova$"Chisq"[2],
## Df:
nl_en_P_anova$"Chi Df"[2],
## P-val:
nl_en_P_anova$"Pr"[2])

model0_nl_en_D2 = lmer(PP2 ~ 1 + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

model1_nl_en_D2 = lmer(PP2 ~ condition + (1|subject) + (1|item) + (0+condition|subject),data_nl_en,
                       REML=FALSE)

nl_en_D2_anova<-anova(model0_nl_en_D2,
                      model1_nl_en_D2)

nl_en_chisq[5,]<-
  ## Chisq:
c(nl_en_D2_anova$"Chisq"[2],
## Df:
nl_en_D2_anova$"Chi Df"[2],
## P-val:
nl_en_D2_anova$"Pr"[2])
@

\subsection{Stan analyses}

<<>>=
## function for setting up data:
prepare_data<-function(col=9){
dat <- list(mu_prior=c(0,0),
            subject=as.integer(factor(data_nl_en$subject)),
            item=as.integer(factor(data_nl_en$item)),
            y=data_nl_en[,col], ## dep. var.
            condition = data_nl_en$condition,
            N = nrow(data_nl_en),
            I = length(unique(data_nl_en$subject)),
            K = length(unique(data_nl_en$item))
)
return(dat)
}

## columns in data:
#V3 V3 9
#D1 NP1 10
#N1 NP2 11
#P PP1 12
#D2 PP2 13
colnames(data_nl_en)[9:13]
@

<<>>=
## columns in data:
#V3 V3 9
#D1 NP1 10
#N1 NP2 11
#P PP1 12
#D2 PP2 13

datV3<-prepare_data(col=9)

summary(datV3$y)

fit_V3 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datV3,
                 pars=params)

print(fit_V3)

mV3<-as.matrix(fit_V3)
head(mV3)
hist(mV3[,2])
hist(mV3[,3])
hist(mV3[,4])
hist(mV3[,5])
hist(mV3[,6])
hist(mV3[,7])


nlenV3results<-c(mean(mV3[,2]),
                 sd(mV3[,2]),
                 quantile(mV3[,2],
                          probs=c(0.025,0.975)),
                mean(mV3[,2]>0))
@


<<>>=
datD1<-prepare_data(col=10)

summary(datD1$y)

fit_D1 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD1,
                 pars=params)

print(fit_D1)

mD1<-as.matrix(fit_D1)
head(mD1)

nlenD1results<-c(mean(mD1[,2]),
                 sd(mD1[,2]),
                 quantile(mD1[,2],
                          probs=c(0.025,0.975)),
                mean(mD1[,2]>0))

@

This analysis looks at the grammaticality-proficiency interaction:

<<>>=
data_nl_enprof<-data_nl_en

m0<-lmer(NP1~condition+scale(proficiency,scale=FALSE)+
           (condition||subject),
         data_nl_enprof)

m1<-lmer(NP1~condition*scale(proficiency,scale=FALSE)+(condition||subject),data_nl_enprof)

summary(m1)

anova(m0,m1)

proficiency<-data_nl_enprof$proficiency-
  mean(data_nl_enprof$proficiency)

interaction<-proficiency*data_nl_enprof$condition

datD1prof <- list(mu_prior=c(0,0,0,0),
            subject=as.integer(factor(data_nl_enprof$subject)),
            item=as.integer(factor(data_nl_enprof$item)),
            y=data_nl_enprof[,10], ## dep. var.
            condition = data_nl_enprof$condition,
            proficiency = proficiency,
            interaction =  interaction,
            N = nrow(data_nl_enprof),
            I = length(unique(data_nl_enprof$subject)),
            K = length(unique(data_nl_enprof$item)))

fit_D1prof <- stan(file="FTVCogSciProficiency.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD1prof,
                 pars=params)

print(fit_D1prof)

mD1prof<-as.matrix(fit_D1prof)
hist(mD1prof[,1])
hist(mD1prof[,2])
hist(mD1prof[,3])
hist(mD1prof[,4])
mean(mD1prof[,4]>0)
quantile(mD1prof[,4],prob=c(0.025,0.975))
mean(mD1prof[,4])

@

Interaction of trial id with grammaticality:

<<>>=
m2<-lmer(NP1~condition+scale(targetpos,scale=FALSE)+(condition||subject),data_nl_en)

m3<-lmer(NP1~condition*scale(targetpos,scale=FALSE)+(condition||subject),data_nl_en)

summary(m3)
## 0.002921, SE 0.01097, t=0.27

anova(m2,m3)
#chisq 0.0743, p=0.7852 
@


<<>>=
datN1<-prepare_data(col=11)

summary(datN1$y)

fit_N1 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datN1,
                 pars=params)

print(fit_N1)

mN1<-as.matrix(fit_N1)
head(mN1)

nlenN1results<-c(mean(mN1[,2]),
                 sd(mN1[,2]),
                 quantile(mN1[,2],
                          probs=c(0.025,0.975)),
                mean(mN1[,2]>0))

@

<<>>=
datP<-prepare_data(col=12)

summary(datP$y)

fit_P <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datP,
                 pars=params)

print(fit_P)

mP<-as.matrix(fit_P)
head(mP)

nlenPresults<-c(mean(mP[,2]),
                 sd(mP[,2]),
                 quantile(mP[,2],
                          probs=c(0.025,0.975)),
                mean(mP[,2]>0))

@

<<>>=
datD2<-prepare_data(col=13)

summary(datD2$y)

fit_D2 <- stan(file="FTVCogSci.Stan",
                 iter=2000,
                 warmup=500,
                 data=datD2,
                 pars=params)

print(fit_D2)

mD2<-as.matrix(fit_D2)
head(mD2)

nlenD2results<-c(mean(mD2[,2]),
                 sd(mD2[,2]),
                 quantile(mD2[,2],
                          probs=c(0.025,0.975)),
                mean(mD2[,2]>0))

@

<<>>=
nlenresults<-rbind(nlenV3results,
      nlenD1results,
      nlenN1results,
      nlenPresults,
      nlenD2results)

nlenresults<-cbind(nlenresults,nl_en_chisq[,c(1,3)])
colnames(nlenresults)<-c("b","SD","2.5th","97.5th",
                         "P(b>0)","Chi-sq","p-value")

rownames(nlenresults)<-c("V3","Det1","N1","Prep","Det2")

@

<<results=tex>>=
xtable(nlenresults)
@

%\section{JAGS models for comparison}

%We also fit models using JAGS \cite{plummer2011jags} in order to allow comparison between the Stan and JAGS posterior distributions. The JAGS models are not presented in the paper. Non-informative priors ($N(\mu=0,\sigma^2=10^5)$) were used for the intercept and effect of Grammaticality, and Wishart priors for the inverse of the variance-covariance matrices for the random effects by subject and by item. In addition, in order to fit a maximal variance-covariance structure by subject and by item, and following the recommendations of \citeA{chungweakly}, weakly informative priors were used for the standard deviations ($Gamma(1.5, 10^{-4})$ priors on the inverse of the variance) and for the correlation (the prior $Beta(1.5,1.5)$ on $(\rho+1)/2$).}

%In all the JAGS models, we ran four chains with 2000 adaptation steps, a burn-in of 5000, and 10,000 samples, with a thinning of 10.

\section{Surprisal calculations}

<<>>=
nlV3 <- read.csv('data/surprisal_nl_V3.csv',header=TRUE)
nlD1 <- read.csv('data/surprisal_nl_Det1.csv',header=TRUE)
enV3 <- read.csv('data/surprisal_en_V3.csv',header=TRUE)
enD1 <- read.csv('data/surprisal_en_Det1.csv',header=TRUE)

xtabs(~condition+item,nlV3)

contrasts(nlV3$condition)<-contr.sum(2)*-1
m1<-lmer(surprisal~condition+(1|item),nlV3)

m1a<-lmer(surprisal~1+(1|item),nlV3)

anova(m1a,m1)
summary(m1)

contrasts(nlD1$condition)<-contr.sum(2)*(-1)
m2a<-lmer(surprisal~1+(1|item),nlD1)
m2<-lmer(surprisal~condition+(1|item),nlD1)

summary(m2)

anova(m2a,m2)

contrasts(enV3$condition)<-contr.sum(2)*-1
m3<-lmer(surprisal~condition+(1|item),enV3)
m3a<-lmer(surprisal~1+(1|item),enV3)

anova(m3,m3a)

contrasts(enD1$condition)<-contr.sum(2)*-1
m4<-lmer(surprisal~condition+(1|item),enD1)
m4a<-lmer(surprisal~1+(1|item),enD1)

anova(m4,m4a)
@





t.test(subset(nlD1,condition=="g")$surprisal,subset(nlD1,condition=="ug")$surprisal,paired=TRUE)


t.test()







@



\end{document}